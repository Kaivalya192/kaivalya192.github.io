const projects = [
  {
    title: 'Vision-Guided Robotic Manipulation (VGR Module)',
    slug: 'vgr',
    image: '/img/vgr.webp',
    desc: 'End-to-end ROS2 pipeline converting detections to calibrated robot poses; UDP/Modbus triggers; sequential pick-and-place and CNC tending.',
    links: [{ label: 'Case Study', href: '#' }],
    badges: ['Deployed', 'Industrial', 'ROS2', 'Calibrated'],
    metrics: [
      { k: 'Latency', v: '~200ms' },
      { k: 'Throughput', v: '3–5 ops/s' },
    ],
    tags: ['ros2', 'perception', 'manipulation', 'industrial'],
    impactRank: 1,
  },
  {
    title: 'Shoonya Recycling — Battery Classification Vision System',
    slug: 'shoonya',
    image: '/img/shoonya.webp',
    desc: 'Multi-level brand classification with YOLO + OCR fusion; ONNX/TensorRT optimized for sub-second industrial latency.',
    links: [{ label: 'Overview', href: '#' }],
    badges: ['Deployed', 'YOLO', 'OCR', 'TensorRT'],
    metrics: [
      { k: 'mAP@50', v: '85.7%' },
      { k: 'Latency', v: '< 0.2s' },
    ],
    tags: ['vision', 'ocr', 'industrial'],
    impactRank: 2,
  },
  {
    title: 'Agentic AI for Half-Humanoid Robot',
    slug: 'agentic',
    image: '/img/agent.webp',
    desc: 'LangGraph-driven multi-turn reasoning loop combining GPT, VLMs, and control APIs; bimanual execution with fallback replanning.',
    links: [{ label: 'Demo', href: '#' }],
    badges: ['Agentic', 'LangGraph', 'VLM', 'Bimanual'],
    metrics: [
      { k: 'Tasks', v: '25+ skills' },
      { k: 'Replan', v: 'auto' },
    ],
    tags: ['ai', 'planning', 'robotics'],
    impactRank: 3,
  },
  {
    title: 'Grasp Detection for Multiple Objects',
    slug: 'grasp',
    image: '/img/grasp.webp',
    desc: '6-DOF grasp generation from RealSense point clouds; dockerized API; robust any-view grasping.',
    links: [{ label: 'Repo', href: 'https://github.com/Kaivalya192/contact_graspnet' }],
    badges: ['6-DOF', 'PointCloud', 'Docker'],
    metrics: [
      { k: 'FPS', v: '~10' },
      { k: 'Sensor', v: 'RealSense' },
    ],
    tags: ['grasping', 'pointcloud', 'perception'],
    impactRank: 4,
  },
  {
    title: '6DOF Live Pose Estimation & Tracking',
    slug: 'pose',
    image: '/img/pose.webp',
    desc: 'Live camera-to-object transform at up to 90 FPS with depth camera; ROS2 package available.',
    links: [
      { label: 'Repo', href: 'https://github.com/Kaivalya192/live-pose' },
      { label: 'ROS2', href: 'https://github.com/Kaivalya192/live-pose-ros' },
    ],
    badges: ['Pose-6D', 'Depth', '90 FPS'],
    metrics: [
      { k: 'FPS', v: '90' },
      { k: 'Camera', v: 'Depth' },
    ],
    tags: ['pose', 'perception', 'ros2'],
    impactRank: 5,
  },
  {
    title: 'Novel 3D Reconstruction (NeRF + LoFTR)',
    slug: 'nerf',
    image: '/img/3d.webp',
    desc: 'NeRF-textured object reconstruction even with poor texture via local feature matching (LoFTR).',
    links: [{ label: 'Repo', href: 'https://github.com/Kaivalya192/Object_Reconstruction' }],
    badges: ['NeRF', 'LoFTR', 'Reconstruction'],
    metrics: [{ k: 'Views', v: 'Sparse OK' }],
    tags: ['nerf', 'sfm', 'perception'],
    impactRank: 6,
  },
  {
    title: 'ROS2 Perception Modules — YOLO & MiDaS Integration',
    slug: 'perception',
    image: '/img/perception.webp',
    desc: 'Modular detection and monocular depth nodes; plug-and-play topics for RViz/robot pipelines.',
    links: [{ label: 'Docs', href: '#' }],
    badges: ['ROS2', 'YOLO', 'MiDaS'],
    metrics: [{ k: 'Nodes', v: '2+' }],
    tags: ['ros2', 'perception'],
    impactRank: 7,
  },
  {
    title: 'YOLOv8 with Segmentation in ROS2',
    slug: 'yolo',
    image: '/img/Yolo.webp',
    desc: 'Real-time object segmentation integrated into a ROS2 graph for robotic perception.',
    links: [{ label: 'Repo', href: 'https://github.com/Kaivalya192/YoloBot_src' }],
    badges: ['YOLOv8', 'Segmentation', 'ROS2'],
    metrics: [{ k: 'FPS', v: 'Realtime' }],
    tags: ['ros2', 'vision'],
    impactRank: 8,
  },
  {
    title: 'Monocular Depth Estimation in ROS2 (MiDaS)',
    slug: 'midas',
    image: '/img/midas.webp',
    desc: 'Single-camera depth for path planning and perception; ROS2 integration.',
    links: [{ label: 'Repo', href: 'https://github.com/Kaivalya192/midas_ros2' }],
    badges: ['MiDaS', 'Depth', 'ROS2'],
    metrics: [{ k: 'Use', v: 'Planning' }],
    tags: ['ros2', 'depth'],
    impactRank: 9,
  },
  {
    title: 'Multi-Purpose Differential Drive Bot in ROS2',
    slug: 'bot',
    image: '/img/bot_spawn.webp',
    desc: 'SLAM + RGB-D vision + control; a reusable ROS2 starter stack.',
    links: [{ label: 'Repo', href: 'https://github.com/Kaivalya192/bot_spawn' }],
    badges: ['SLAM', 'RGB-D', 'ROS2'],
    tags: ['robot', 'ros2'],
    impactRank: 10,
  },
  {
    title: 'PathFinder Bot with PID (SVNIT MindBend 2nd)',
    slug: 'pathfinder',
    image: '/img/pathfinder.webp',
    desc: 'Wall-maze solver on Arduino with PID; placed 2nd at MindBend — SVNIT.',
    links: [{ label: 'Repo', href: 'https://github.com/Kaivalya192/WallMazeSolver' }],
    badges: ['Arduino', 'PID', 'Award'],
    tags: ['embedded', 'robot'],
    impactRank: 11,
  },
  {
    title: 'Line Follower Maze-solving Bot (IITB Micromouse)',
    slug: 'lms',
    image: '/img/LMS.webp',
    desc: '5-IR sensor array; dry-run shortest path; qualified IITB Micromouse.',
    links: [{ label: 'Repo', href: 'https://github.com/Kaivalya192/LMS' }],
    badges: ['PID', 'LineFollower', 'Competition'],
    tags: ['embedded', 'robot'],
    impactRank: 12,
  },
  {
    title: 'Real-Time Voice Activity Detection (VAD)',
    slug: 'vad',
    image: '/img/vad.webp',
    desc: 'Lightweight VAD with live terminal feedback and custom chunk analysis.',
    links: [{ label: 'Repo', href: 'https://github.com/Kaivalya192/VAD_Barry' }],
    badges: ['Audio', 'Realtime'],
    tags: ['audio', 'utils'],
    impactRank: 13,
  },
];

export default projects;
