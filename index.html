<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=800">
    <link rel="icon" type="image/png" href="img/avatar.webp">
    <title>Kaivalya Shah</title>
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic">
    <style>
        body {
            font-family: 'Lato', sans-serif;
            background-color: #eef2f7;
            margin: 0;
            padding: 0;
            color: #222;
            text-align: justify;
        }
        
        .container {
            width: 85%;
            max-width: 1000px;
            margin: 40px auto;
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
        }
        
        h1, h2 {
            color: #0056b3;
            text-align: center;
        }
        
        a {
            color: #0056b3;
            text-decoration: none;
            font-weight: bold;
            transition: color 0.3s;
        }
        
        a:hover {
            color: #f57c00;
        }
        
        .profile {
            display: flex;
            align-items: center;
            justify-content: center;
            padding: 30px;
            border-bottom: 3px solid #ddd;
            gap: 20px;
            text-align: left;
        }
        
        .profile img {
            width: 180px;
            height: 180px;
            border-radius: 50%;
            border: 4px solid #ddd;
        }
        
        .profile-text {
            max-width: 600px;
            font-size: 18px;
        }
        
        .section {
            margin: 30px 0;
            padding: 20px;
            border-left: 6px solid #0056b3;
            background: #fdfdfd;
            box-shadow: 2px 2px 10px rgba(0, 0, 0, 0.05);
            border-radius: 6px;
        }
        
        .section h2 {
            margin-bottom: 15px;
            font-size: 24px;
        }
        
        .contact a {
            margin-right: 15px;
            font-size: 16px;
        }
        
        table {
            width: 100%;
            border-collapse: separate;
            border-spacing: 20px 15px;
        }
        
        td {
            vertical-align: middle;
            padding: 15px;
            font-size: 18px;
        }
        
        .project-img img {
            width: 180px;
            height: 180px;
            border-radius: 8px;
            box-shadow: 2px 2px 10px rgba(0, 0, 0, 0.1);
        }


        .experience {
            margin-bottom: 20px;
            padding: 15px;
            background: #f9f9f9;
            border-radius: 6px;
            box-shadow: 2px 2px 10px rgba(0, 0, 0, 0.05);
        }
        
        .experience-header {
            font-size: 20px;
            font-weight: bold;
            color: #0056b3;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }
        
        .experience-date {
            font-size: 16px;
            color: #777;
            font-style: italic;
        }
        
        .location {
            font-size: 16px;
            color: #666;
            margin-top: 3px;
        }
        
        .experience-role {
            font-size: 18px;
            font-weight: bold;
            color: #333;
            margin-top: 5px;
        }
        
        .experience ul {
            padding-left: 20px;
            font-size: 16px;
            color: #444;
        }
        
        .experience ul li {
            margin-bottom: 5px;
        }
        
        @media screen and (max-width: 768px) {
            .profile {
                flex-direction: column;
                text-align: center;
            }
        
            .profile img {
                margin-bottom: 10px;
            }
        
            table {
                display: block;
                width: 100%;
            }
        
            td {
                display: block;
                text-align: center;
            }
        
            .project-img img {
                width: 100%;
                height: auto;
            }
        }        
    </style>
</head>
<body>
    
    <div class="container">
        <div class="profile">
            <img src="img/avtr.webp" alt="Kaivalya Shah">
            <div class="profile-text">
                <h1>Kaivalya Shah</h1>
        
                <div class="info">
                    <p><strong>Degree:</strong> Computer Engineering (Minor in Robotics)</p>
                    <p><strong>Institution:</strong> Pandit Deendayal Energy University (PDEU)</p>
                    <p><strong>Domains:</strong> Computer Vision, Robotics, Vision-Based Automation</p>
                </div>
        
                <div class="contact-links">
                    <strong>Contact:</strong>
                    <a href="mailto:kaivalyashah192@gmail.com"> Email</a> |
                    <a href="pdf/cv.pdf">CV</a> |
                    <a href="https://github.com/Kaivalya192" target="_blank">GitHub</a> |
                    <a href="https://www.linkedin.com/in/kaivalya192" target="_blank">LinkedIn</a>
                </div>
            </div>
        </div>        

        <div class="section">
            <h2>Experience</h2>
      
            <div class="experience">
              <div class="experience-header">
                <strong>Sastra Robotics (Startup), IITGN</strong>
                <span class="experience-date">Sep 2024 – Present</span>
              </div>
              <div class="location">Gandhinagar, India</div>
              <div class="experience-role">Computer Vision Intern</div>
              <ul>
                <li>Optimized multiple AI vision modules for Jetson Orin NX deployment.</li>
                <li>Developed modular gripper system with real-time TCP and WebSocket communication.</li>
                <li>Integrated motor control between ESP32 and Ethernet module using UART/Serial and socket communication.</li>
              </ul>
            </div>
      
            <div class="experience">
              <div class="experience-header">
                <strong>IITGN Robotics Lab</strong>
                <span class="experience-date">May 2024 – Jul 2024</span>
              </div>
              <div class="location">Gandhinagar, India</div>
              <div class="experience-role">Research Intern</div>
              <ul>
                <li>Led development of real-time 6D pose estimation with < 5cm error on live objects.</li>
                <li>Created a 3D reconstruction pipeline improving scene fidelity by 20%.</li>
              </ul>
            </div>
      
            <div class="experience">
              <div class="experience-header">
                <strong>iNav Labs (Startup), PDEU</strong>
                <span class="experience-date">May 2023 – Jul 2023</span>
              </div>
              <div class="location">Gandhinagar, India</div>
              <div class="experience-role">ROS Developer</div>
              <ul>
                <li>Developed ROS packages for an autonomous car prototype using Jetson Nano.</li>
              </ul>
            </div>
          </div>    
        
        
        <div class="section">
            <h2>Skills</h2>
            <div class="skills-grid">
              <p><strong>Programming Languages:</strong> Python, C++, Java, R, MATLAB</p>
              <p><strong>Libraries & Frameworks:</strong> Asyncio, ZeroMQ, PyTorch, TensorFlow, Open3D, Flask, NumPy</p>
              <p><strong>Computer Vision & AI:</strong> CLIP, ViT, VLM/LLMs, NeRF, LoFTR</p>
              <p><strong>Theory:</strong> Robotics and Control Systems</p>
              <p><strong>Edge Device Optimization:</strong> Jetson Orin NX</p>
              <p><strong>Technologies:</strong> ROS, Gazebo, SLAM, Nav2, CUDA, WebSockets</p>
              <p><strong>Hardware:</strong> Arduino, ESP32, Raspberry Pi</p>
              <p><strong>Tools:</strong> Docker, Conda, Git, Fusion 360 (URDF)</p>
            </div>
        </div>

        <div class="section">
            <h2>Projects</h2>
            <table>
              <tr>
                <td class="project-img"><img src='img/gs.jpg'></td>
                <td>
                  <a href="https://github.com/Kaivalya192/gripper_system_page" target="_blank">Gripper System with SDK + UI</a>
                  <p>Modular, node-based system for controlling and monitoring a robotic gripper with real-time visual feedback and perception for interactive manipulation.</p>
                  <p>Includes a user interface and SDK for system control and visualization. Built with ZeroMQ, Asyncio, and multi-threaded architecture.</p>
                </td>
              </tr>
          
              <tr>
                <td class="project-img"><img src='img/graspnet.jpg'></td>
                <td>
                  <a href="https://github.com/Kaivalya192/contact_graspnet" target="_blank">Grasp Detection for Multiple Objects</a>
                  <p>6-DoF grasp detection in cluttered scenes using point clouds from RealSense depth cameras and Open3D TSDF integration.</p>
                  <p>Implements learning-based grasp candidate generation and evaluation via a Dockerized API, enabling robust any-view grasping on edge devices.</p>
                </td>
              </tr>
          
              <tr>
                <td class="project-img"><img src='img/pose.webp'></td>
                <td>
                  <a href="https://github.com/Kaivalya192/live-pose" target="_blank">Live Pose – 6DoF Pose Estimation</a>
                  <p>Python package for real-time 6-DoF pose estimation of objects using CAD models and depth camera input.</p>
                  <p>Cross-platform deployment supported via Docker on Jetson and native Windows. Includes object masking and custom 3D model support.</p>
                </td>
              </tr>
          
              <tr>
                <td class="project-img"><img src='img/3d.webp'></td>
                <td>
                  <a href="https://github.com/Kaivalya192/Object_Reconstruction" target="_blank">Object-Level 3D Reconstruction</a>
                  <p>Reconstructs high-fidelity object shapes from RGB-D data using NeRF and LoFTR.</p>
                  <p>Interactive mask-based segmentation and boundary selection enable accurate geometry extraction, with 15+ stars on GitHub.</p>
                </td>
              </tr>
          
              <tr>
                <td class="project-img"><img src='img/vad.png'></td>
                <td>
                  <a href="https://github.com/Kaivalya192/VAD_Barry" target="_blank">Real-Time Voice Activity Detection (VAD)</a>
                  <p>Lightweight speech detection tool using a deep learning model (Silero) for live microphone input.</p>
                  <p>Terminal-based feedback with modular support for noise suppression, speaker diarization, and future audio pipeline extensions.</p>
                </td>
              </tr>
          
              <tr>
                <td class="project-img"><img src='img/obj_prop.png'></td>
                <td>
                  <a href="https://github.com/Kaivalya192/Object-Property-Detection" target="_blank">Object Property Detection</a>
                  <p>System to estimate material, dimensions, weight, and surface friction from images using VLMs, LLMs, CLIP, and SAM2.</p>
                  <p>Tested and compared pipelines for speed and accuracy to aid robotic grasp planning and manipulation.</p>
                </td>
              </tr>
          
              <tr>
                <td class="project-img"><img src='img/bot_spawn.webp'></td>
                <td>
                  <a href="https://github.com/Kaivalya192/bot_spawn" target="_blank">Multi-Purpose Differential Drive Robot</a>
                  <p>Versatile ROS2 simulation environment in Gazebo with modular sensors and full SLAM + RGB-D vision stack.</p>
                  <p>Supports YOLO, MiDaS, teleoperation, and real-time 3D mapping for indoor navigation scenarios.</p>
                </td>
              </tr>
          
              <tr>
                <td class="project-img"><img src='img/Yolo.webp'></td>
                <td>
                  <a href="https://github.com/Kaivalya192/YoloBot_src" target="_blank">ROS2 Perception Modules – YOLO + MiDaS</a>
                  <p>Modular ROS2 nodes for real-time object detection (YOLOv8) and depth estimation (MiDaS) integrated with Gazebo streams.</p>
                  <p>Publishes detection and depth topics for RViz visualization, designed to be plug-and-play with bot\_spawn.</p>
                </td>
              </tr>
          
              <tr>
                <td class="project-img"><img src='img/gestureCar.gif'></td>
                <td>
                  <a href="https://github.com/Kaivalya192/gesture_car" target="_blank">Gesture Controlled Car</a>
                  <p>Wireless ESP32/ESP8266-based car using computer vision for gesture commands.</p>
                  <p>Real-time control implemented with custom hardware and MediaPipe for detection.</p>
                </td>
              </tr>
          
              <tr>
                <td class="project-img"><img src='img/pathfinder.webp'></td>
                <td>
                  <a href="https://github.com/Kaivalya192/WallMazeSolver" target="_blank">Wall Maze Solver Bot</a>
                  <p>Robot designed with PID control and obstacle avoidance, built using Arduino.</p>
                  <p>Winner of 2nd Prize @ MindBend, SVNIT.</p>
                </td>
              </tr>
          
              <tr>
                <td class="project-img"><img src='img/LMS.webp'></td>
                <td>
                  <a href="https://github.com/Kaivalya192/LMS" target="_blank">Line Following Maze Solver</a>
                  <p>PID-based bot using 5-IR sensor array and dry-run logic to solve printed mazes efficiently.</p>
                  <p>Finalist at IIT Bombay Techfest (Micromouse competition).</p>
                </td>
              </tr>
          
            </table>
          </div>
          
    </div>
</body>
</html>
